{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64de3406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/2024/ds2/119008303/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pythae.models import AE, AEConfig, BaseAEConfig\n",
    "from pythae.trainers import BaseTrainerConfig\n",
    "from pythae.pipelines.training import TrainingPipeline\n",
    "from pythae.models.nn import BaseEncoder, BaseDecoder\n",
    "from pythae.models.base.base_utils import ModelOutput\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff1fab85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pos_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000-JAM.wav</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001-JAM.wav</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002-JAM.wav</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003-JAM.wav</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004-JAM.wav</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23163</th>\n",
       "      <td>23163-StMARTIN.wav</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23164</th>\n",
       "      <td>23164-StMARTIN.wav</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23165</th>\n",
       "      <td>23165-StMARTIN.wav</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23166</th>\n",
       "      <td>23166-StMARTIN.wav</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23167</th>\n",
       "      <td>23167-StMARTIN.wav</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23168 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  pos_label\n",
       "0           00000-JAM.wav        0.0\n",
       "1           00001-JAM.wav        1.0\n",
       "2           00002-JAM.wav        1.0\n",
       "3           00003-JAM.wav        1.0\n",
       "4           00004-JAM.wav        1.0\n",
       "...                   ...        ...\n",
       "23163  23163-StMARTIN.wav        0.0\n",
       "23164  23164-StMARTIN.wav        0.0\n",
       "23165  23165-StMARTIN.wav        0.0\n",
       "23166  23166-StMARTIN.wav        0.0\n",
       "23167  23167-StMARTIN.wav        0.0\n",
       "\n",
       "[23168 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=pd.read_csv(\"/users/2024/ds2/119008303/Documents/ProjetDeepG/Xtrain.csv\")\n",
    "Y_train=pd.read_csv(\"/users/2024/ds2/119008303/Documents/ProjetDeepG/Y_train_ofTdMHi.csv\")\n",
    "#On enlève l'index dupliqué\n",
    "X_train=X_train.drop(\"Unnamed: 0\",axis=1)\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c23a6b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23168 13718 9450\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mean(rms)</th>\n",
       "      <th>std(rms)</th>\n",
       "      <th>min(rms)</th>\n",
       "      <th>max(rms)</th>\n",
       "      <th>mean(sc)</th>\n",
       "      <th>std(sc)</th>\n",
       "      <th>min(sc)</th>\n",
       "      <th>max(sc)</th>\n",
       "      <th>mean(sb)</th>\n",
       "      <th>std(sb)</th>\n",
       "      <th>min(sb)</th>\n",
       "      <th>max(sb)</th>\n",
       "      <th>mean(sl)</th>\n",
       "      <th>std(sl)</th>\n",
       "      <th>min(sl)</th>\n",
       "      <th>max(sl)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000-JAM.wav</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>33091.410037</td>\n",
       "      <td>1476.154209</td>\n",
       "      <td>29273.938993</td>\n",
       "      <td>36801.024729</td>\n",
       "      <td>24774.591555</td>\n",
       "      <td>795.562058</td>\n",
       "      <td>21782.369512</td>\n",
       "      <td>26305.819243</td>\n",
       "      <td>0.019416</td>\n",
       "      <td>0.006762</td>\n",
       "      <td>0.009422</td>\n",
       "      <td>0.073818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00005-JAM.wav</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>33408.695775</td>\n",
       "      <td>3477.503462</td>\n",
       "      <td>28744.581298</td>\n",
       "      <td>50177.904590</td>\n",
       "      <td>24978.507782</td>\n",
       "      <td>830.793102</td>\n",
       "      <td>22465.553924</td>\n",
       "      <td>28356.171977</td>\n",
       "      <td>0.018873</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.009319</td>\n",
       "      <td>0.036378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00009-JAM.wav</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>33355.961273</td>\n",
       "      <td>2047.149337</td>\n",
       "      <td>29002.014318</td>\n",
       "      <td>41179.611425</td>\n",
       "      <td>25138.524228</td>\n",
       "      <td>786.467515</td>\n",
       "      <td>23152.621051</td>\n",
       "      <td>27995.171416</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.066202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00010-JAM.wav</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>33783.752899</td>\n",
       "      <td>2431.886399</td>\n",
       "      <td>30078.844408</td>\n",
       "      <td>43850.162074</td>\n",
       "      <td>24944.966785</td>\n",
       "      <td>706.308967</td>\n",
       "      <td>22931.269985</td>\n",
       "      <td>26345.153437</td>\n",
       "      <td>0.019943</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>0.060732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00014-JAM.wav</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>32800.629770</td>\n",
       "      <td>2199.601830</td>\n",
       "      <td>23771.068590</td>\n",
       "      <td>41577.983044</td>\n",
       "      <td>24968.056369</td>\n",
       "      <td>984.470774</td>\n",
       "      <td>20853.459473</td>\n",
       "      <td>29738.749560</td>\n",
       "      <td>0.019289</td>\n",
       "      <td>0.006087</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.059331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23163</th>\n",
       "      <td>23163-StMARTIN.wav</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>33722.181712</td>\n",
       "      <td>6594.427299</td>\n",
       "      <td>16122.779232</td>\n",
       "      <td>46675.454300</td>\n",
       "      <td>24863.133950</td>\n",
       "      <td>1940.818239</td>\n",
       "      <td>16260.874707</td>\n",
       "      <td>28774.001127</td>\n",
       "      <td>0.016198</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.031867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23164</th>\n",
       "      <td>23164-StMARTIN.wav</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.017226</td>\n",
       "      <td>29928.163405</td>\n",
       "      <td>8505.604412</td>\n",
       "      <td>16122.779232</td>\n",
       "      <td>46675.454300</td>\n",
       "      <td>23937.977418</td>\n",
       "      <td>2661.234268</td>\n",
       "      <td>16260.874707</td>\n",
       "      <td>28774.001127</td>\n",
       "      <td>0.013391</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.052123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23165</th>\n",
       "      <td>23165-StMARTIN.wav</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.021214</td>\n",
       "      <td>26494.644501</td>\n",
       "      <td>7454.221171</td>\n",
       "      <td>16569.821473</td>\n",
       "      <td>45249.640123</td>\n",
       "      <td>23076.817821</td>\n",
       "      <td>2543.909457</td>\n",
       "      <td>16189.199279</td>\n",
       "      <td>28311.672579</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.051902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23166</th>\n",
       "      <td>23166-StMARTIN.wav</td>\n",
       "      <td>0.014010</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.026707</td>\n",
       "      <td>20982.874469</td>\n",
       "      <td>2426.708451</td>\n",
       "      <td>16905.249559</td>\n",
       "      <td>28325.176302</td>\n",
       "      <td>22216.843367</td>\n",
       "      <td>1165.290580</td>\n",
       "      <td>20056.578526</td>\n",
       "      <td>25350.175433</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.011945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23167</th>\n",
       "      <td>23167-StMARTIN.wav</td>\n",
       "      <td>0.012639</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.028727</td>\n",
       "      <td>21473.234387</td>\n",
       "      <td>3707.178854</td>\n",
       "      <td>16905.249559</td>\n",
       "      <td>33589.842966</td>\n",
       "      <td>21831.087556</td>\n",
       "      <td>1513.646712</td>\n",
       "      <td>16432.623004</td>\n",
       "      <td>26179.365157</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.021524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13718 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  mean(rms)  std(rms)  min(rms)  max(rms)  \\\n",
       "0           00000-JAM.wav   0.000306  0.000067  0.000188  0.000488   \n",
       "5           00005-JAM.wav   0.000315  0.000133  0.000199  0.000914   \n",
       "9           00009-JAM.wav   0.000306  0.000101  0.000197  0.000794   \n",
       "10          00010-JAM.wav   0.000325  0.000091  0.000203  0.000699   \n",
       "14          00014-JAM.wav   0.000307  0.000138  0.000182  0.000969   \n",
       "...                   ...        ...       ...       ...       ...   \n",
       "23163  23163-StMARTIN.wav   0.001614  0.003077  0.000066  0.015190   \n",
       "23164  23164-StMARTIN.wav   0.005424  0.006420  0.000066  0.017226   \n",
       "23165  23165-StMARTIN.wav   0.007480  0.006840  0.000065  0.021214   \n",
       "23166  23166-StMARTIN.wav   0.014010  0.003323  0.000532  0.026707   \n",
       "23167  23167-StMARTIN.wav   0.012639  0.006017  0.000156  0.028727   \n",
       "\n",
       "           mean(sc)      std(sc)       min(sc)       max(sc)      mean(sb)  \\\n",
       "0      33091.410037  1476.154209  29273.938993  36801.024729  24774.591555   \n",
       "5      33408.695775  3477.503462  28744.581298  50177.904590  24978.507782   \n",
       "9      33355.961273  2047.149337  29002.014318  41179.611425  25138.524228   \n",
       "10     33783.752899  2431.886399  30078.844408  43850.162074  24944.966785   \n",
       "14     32800.629770  2199.601830  23771.068590  41577.983044  24968.056369   \n",
       "...             ...          ...           ...           ...           ...   \n",
       "23163  33722.181712  6594.427299  16122.779232  46675.454300  24863.133950   \n",
       "23164  29928.163405  8505.604412  16122.779232  46675.454300  23937.977418   \n",
       "23165  26494.644501  7454.221171  16569.821473  45249.640123  23076.817821   \n",
       "23166  20982.874469  2426.708451  16905.249559  28325.176302  22216.843367   \n",
       "23167  21473.234387  3707.178854  16905.249559  33589.842966  21831.087556   \n",
       "\n",
       "           std(sb)       min(sb)       max(sb)  mean(sl)   std(sl)   min(sl)  \\\n",
       "0       795.562058  21782.369512  26305.819243  0.019416  0.006762  0.009422   \n",
       "5       830.793102  22465.553924  28356.171977  0.018873  0.004171  0.009319   \n",
       "9       786.467515  23152.621051  27995.171416  0.019868  0.006567  0.009355   \n",
       "10      706.308967  22931.269985  26345.153437  0.019943  0.006633  0.010586   \n",
       "14      984.470774  20853.459473  29738.749560  0.019289  0.006087  0.005102   \n",
       "...            ...           ...           ...       ...       ...       ...   \n",
       "23163  1940.818239  16260.874707  28774.001127  0.016198  0.007596  0.000377   \n",
       "23164  2661.234268  16260.874707  28774.001127  0.013391  0.011600  0.000377   \n",
       "23165  2543.909457  16189.199279  28311.672579  0.008938  0.010593  0.000489   \n",
       "23166  1165.290580  20056.578526  25350.175433  0.001703  0.001460  0.000489   \n",
       "23167  1513.646712  16432.623004  26179.365157  0.003057  0.004236  0.000489   \n",
       "\n",
       "        max(sl)  \n",
       "0      0.073818  \n",
       "5      0.036378  \n",
       "9      0.066202  \n",
       "10     0.060732  \n",
       "14     0.059331  \n",
       "...         ...  \n",
       "23163  0.031867  \n",
       "23164  0.052123  \n",
       "23165  0.051902  \n",
       "23166  0.011945  \n",
       "23167  0.021524  \n",
       "\n",
       "[13718 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On regroupe X_train avec leur classification Y_train pour pouvoir les séparer selon leur classification\n",
    "total=pd.merge(X_train,Y_train, on=\"id\")\n",
    "class0=total[total[\"pos_label\"]==0.0]\n",
    "class1=total[total[\"pos_label\"]==1.0]\n",
    "print(len(total),len(class0),len(class1))\n",
    "X_0,Y_0=class0.drop(\"pos_label\",axis=1),class0[\"pos_label\"]\n",
    "X_1,Y_1=class1.drop(\"pos_label\",axis=1),class1[\"pos_label\"]\n",
    "X_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e3f2018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13718, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On retire les id des X_i,Y_i pour les passer dans leur AE respectif\n",
    "Xt0=pd.DataFrame(X_0.drop(\"id\",axis=1)).to_numpy()\n",
    "Xt1=pd.DataFrame(X_1.drop(\"id\",axis=1)).to_numpy()\n",
    "Yt0=pd.DataFrame(Y_0).to_numpy()\n",
    "Yt1=pd.DataFrame(Y_1).to_numpy()\n",
    "Xt0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e7edf356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13718, 16)\n",
      "(13718, 1, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "#Ajustement de la dimension pour l'AE\n",
    "print(Xt0.shape)\n",
    "test=Xt0.reshape(Xt0.shape[0],1,4,4).astype('float32') #add an additional dimension to\n",
    "test2=Xt1.reshape(Xt1.shape[0],1,4,4).astype('float32')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "80525086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensions:\n",
    "encod_input_shape=(1,4,4)\n",
    "decod_input_shape=(0,0,0)\n",
    "batch_size=38  #(13718/38=361)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6652b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crétaion de l'encodeur\n",
    "class my_encoder(BaseEncoder):\n",
    "    def __init__(self, args: BaseAEConfig):\n",
    "        BaseEncoder.__init__(self)\n",
    "\n",
    "        self.input_dim = (1,4,4)\n",
    "        self.latent_dim = args.latent_dim\n",
    "        self.n_channels = 1\n",
    "\n",
    "        layers = nn.ModuleList()\n",
    "\n",
    "        layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(self.n_channels, 128, kernel_size=(2,2),padding='same'),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(128,256, kernel_size=(2,2),padding='same'), \n",
    "                nn.BatchNorm2d(256), \n",
    "                nn.ReLU()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(256,512, kernel_size=(2,2),padding='same'),\n",
    "                nn.BatchNorm2d(512), \n",
    "                nn.ReLU()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(512,1024, kernel_size=(2,2)), \n",
    "                nn.BatchNorm2d(1024), \n",
    "                nn.ReLU()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.layers = layers\n",
    "        self.depth = len(layers)\n",
    "        self.embedding = nn.Linear(9216, args.latent_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, output_layer_levels: List[int] = None):\n",
    "        output = ModelOutput()\n",
    "        max_depth = self.depth\n",
    "\n",
    "        if output_layer_levels is not None:\n",
    "            assert all(\n",
    "                self.depth >= levels > 0 or levels == -1\n",
    "                for levels in output_layer_levels\n",
    "            ), (\n",
    "                f\"Cannot output layer deeper than depth ({self.depth}).\"\n",
    "                f\"Got ({output_layer_levels}).\"\n",
    "            )\n",
    "\n",
    "            if -1 in output_layer_levels:\n",
    "                max_depth = self.depth\n",
    "            else:\n",
    "                max_depth = max(output_layer_levels)\n",
    "\n",
    "        out = x\n",
    "        \n",
    "        for i in range(max_depth):\n",
    "            out = self.layers[i](out)\n",
    "\n",
    "            if output_layer_levels is not None:\n",
    "                if i + 1 in output_layer_levels:\n",
    "                    output[f\"embedding_layer_{i+1}\"] = out\n",
    "            if i + 1 == self.depth:\n",
    "                output[\"embedding\"] = self.embedding(out.reshape(x.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2c53a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du décodeur\n",
    "class my_decoder(BaseDecoder):\n",
    "    def __init__(self, args: dict):\n",
    "        BaseDecoder.__init__(self)\n",
    "        self.input_dim = (38,32)\n",
    "        self.latent_dim = args.latent_dim\n",
    "        self.n_channels = 1\n",
    "\n",
    "        layers = nn.ModuleList()\n",
    "                                # ((n,i),(i,p))\n",
    "        layers.append(nn.Linear(args.latent_dim, 1024 * 4 * 4))\n",
    "\n",
    "        layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(1024, 512, 3, 2),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(512, 256, 3, 2, output_padding=1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(\n",
    "                    256, self.n_channels, 3, 2, output_padding=1\n",
    "                ),\n",
    "                nn.Sigmoid(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.layers = layers\n",
    "        self.depth = len(layers)\n",
    "\n",
    "    def forward(self, z: torch.Tensor, output_layer_levels: List[int] = None):\n",
    "        output = ModelOutput()\n",
    "        max_depth = self.depth\n",
    "\n",
    "        if output_layer_levels is not None:\n",
    "            assert all(\n",
    "                self.depth >= levels > 0 or levels == -1\n",
    "                for levels in output_layer_levels\n",
    "            ), (\n",
    "                f\"Cannot output layer deeper than depth ({self.depth}).\"\n",
    "                f\"Got ({output_layer_levels})\"\n",
    "            )\n",
    "\n",
    "            if -1 in output_layer_levels:\n",
    "                max_depth = self.depth\n",
    "            else:\n",
    "                max_depth = max(output_layer_levels)\n",
    "\n",
    "        out = z\n",
    "\n",
    "        for i in range(max_depth):\n",
    "            out = self.layers[i](out)\n",
    "\n",
    "            if i == 0:\n",
    "                out = out.reshape(z.shape[0], 1024, 4, 4)\n",
    "\n",
    "            if output_layer_levels is not None:\n",
    "                if i + 1 in output_layer_levels:\n",
    "                    output[f\"reconstruction_layer_{i+1}\"] = out\n",
    "\n",
    "            if i + 1 == self.depth:\n",
    "                output[\"reconstruction\"] = out\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "74f3d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création de l'AE pour la classe 0:\n",
    "config0 = BaseTrainerConfig(\n",
    "    output_dir='my_model',\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=38,\n",
    "    per_device_eval_batch_size=38,\n",
    "    num_epochs=10, # Change this to train the model a bit more\n",
    "    )\n",
    "\n",
    "model_config0 = AEConfig(input_dim=(13718,1,4,4), latent_dim=32)\n",
    "\n",
    "model0 = AE(\n",
    "    model_config=model_config0,\n",
    "    encoder=my_encoder(model_config0), \n",
    "    decoder = my_decoder(model_config0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ca6b28de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TrainingPipeline(\n",
    "    training_config=config0,\n",
    "    model=model0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0a962d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing train data...\n",
      "Checking train dataset...\n",
      "Preprocessing eval data...\n",
      "\n",
      "Checking eval dataset...\n",
      "Using Base Trainer\n",
      "\n"
     ]
    },
    {
     "ename": "ModelError",
     "evalue": "Error when calling forward method from model. Potential issues: \n - Wrong model architecture -> check encoder, decoder and metric architecture if you provide yours \n - The data input dimension provided is wrong -> when no encoder, decoder or metric provided, a network is built automatically but requires the shape of the flatten input data.\nException raised: <class 'RuntimeError'> with message: The size of tensor a (1764) must match the size of tensor b (16) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/users/2024/ds2/119008303/.local/lib/python3.11/site-packages/pythae/trainers/base_trainer/base_trainer.py:313\u001b[0m, in \u001b[0;36mBaseTrainer._run_model_sanity_check\u001b[0;34m(self, model, loader)\u001b[0m\n\u001b[1;32m    312\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_inputs_to_device(inputs)\n\u001b[0;32m--> 313\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/users/2024/ds2/119008303/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/users/2024/ds2/119008303/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/users/2024/ds2/119008303/.local/lib/python3.11/site-packages/pythae/models/ae/ae_model.py:79\u001b[0m, in \u001b[0;36mAE.forward\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m recon_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreconstruction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 79\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m output \u001b[38;5;241m=\u001b[39m ModelOutput(loss\u001b[38;5;241m=\u001b[39mloss, recon_x\u001b[38;5;241m=\u001b[39mrecon_x, z\u001b[38;5;241m=\u001b[39mz)\n",
      "File \u001b[0;32m/users/2024/ds2/119008303/.local/lib/python3.11/site-packages/pythae/models/ae/ae_model.py:87\u001b[0m, in \u001b[0;36mAE.loss_function\u001b[0;34m(self, recon_x, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, recon_x, x):\n\u001b[0;32m---> 87\u001b[0m     MSE \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecon_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MSE\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/users/2024/ds2/119008303/.local/lib/python3.11/site-packages/torch/nn/functional.py:3328\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3326\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3328\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m/users/2024/ds2/119008303/.local/lib/python3.11/site-packages/torch/functional.py:73\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1764) must match the size of tensor b (16) at non-singleton dimension 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYt0\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/users/2024/ds2/119008303/.local/lib/python3.11/site-packages/pythae/pipelines/training.py:235\u001b[0m, in \u001b[0;36mTrainingPipeline.__call__\u001b[0;34m(self, train_data, eval_data, callbacks)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_config, BaseTrainerConfig):\n\u001b[1;32m    234\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Base Trainer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 235\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m \u001b[43mBaseTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provided training config is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/users/2024/ds2/119008303/.local/lib/python3.11/site-packages/pythae/trainers/base_trainer/base_trainer.py:139\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[0;34m(self, model, train_dataset, eval_dataset, training_config, callbacks)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# run sanity check on the model\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_model_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_main_process:\n\u001b[1;32m    142\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel passed sanity check !\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReady for training.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/users/2024/ds2/119008303/.local/lib/python3.11/site-packages/pythae/trainers/base_trainer/base_trainer.py:316\u001b[0m, in \u001b[0;36mBaseTrainer._run_model_sanity_check\u001b[0;34m(self, model, loader)\u001b[0m\n\u001b[1;32m    313\u001b[0m     model(train_dataset)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ModelError(\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when calling forward method from model. Potential issues: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Wrong model architecture -> check encoder, decoder and metric architecture if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou provide yours \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - The data input dimension provided is wrong -> when no encoder, decoder or metric \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovided, a network is built automatically but requires the shape of the flatten \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput data.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException raised: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with message: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m    324\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mModelError\u001b[0m: Error when calling forward method from model. Potential issues: \n - Wrong model architecture -> check encoder, decoder and metric architecture if you provide yours \n - The data input dimension provided is wrong -> when no encoder, decoder or metric provided, a network is built automatically but requires the shape of the flatten input data.\nException raised: <class 'RuntimeError'> with message: The size of tensor a (1764) must match the size of tensor b (16) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "pipeline(\n",
    "    train_data=test,\n",
    "    eval_data=Yt0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199a7f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833accff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "334ce3de",
   "metadata": {},
   "source": [
    "Essai avec Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc45d9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/lib64/python3.11/site-packages (from tensorflow) (1.24.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.11/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.11/site-packages (from tensorflow) (65.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/lib64/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/lib64/python3.11/site-packages (from tensorflow) (1.48.4)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /users/2024/ds2/119008303/.local/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/lib64/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a590578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1726ef52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10288, 16)\n",
      "(10288, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "#Création de l'échatillon train et test \n",
    "seed=20\n",
    "X0tr,X0te=train_test_split(Xt0,random_state=seed)\n",
    "Y1tr,Y1te=train_test_split(Yt0,random_state=seed)\n",
    "X1tr,X1te=train_test_split(Xt1,random_state=seed)\n",
    "Y1tr,Y0te=train_test_split(Yt1,random_state=seed)\n",
    "\n",
    "#Ajustement de la dimension pour l'AE simple\n",
    "print(X0tr.shape)\n",
    "flow0=X0tr.reshape(X0tr.shape[0],4,4).astype('float32')#add an additional dimension to\n",
    "flow0te=X0te.reshape(X0te.shape[0],4,4).astype('float32')\n",
    "flow1=X1tr.reshape(X1tr.shape[0],4,4).astype('float32')\n",
    "print(flow0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c65210e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(latent_dim, activation='relu'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(16, activation='sigmoid'),\n",
    "      layers.Reshape((4, 4))\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b34201c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(latent_dim)\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0006a4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "322/322 [==============================] - 1s 1ms/step - loss: 340537888.0000 - val_loss: 340964320.0000\n",
      "Epoch 2/10\n",
      "322/322 [==============================] - 0s 811us/step - loss: 340536992.0000 - val_loss: 340964192.0000\n",
      "Epoch 3/10\n",
      "322/322 [==============================] - 0s 841us/step - loss: 340536992.0000 - val_loss: 340964192.0000\n",
      "Epoch 4/10\n",
      "322/322 [==============================] - 0s 826us/step - loss: 340536832.0000 - val_loss: 340964192.0000\n",
      "Epoch 5/10\n",
      "322/322 [==============================] - 0s 835us/step - loss: 340536928.0000 - val_loss: 340964192.0000\n",
      "Epoch 6/10\n",
      "322/322 [==============================] - 0s 826us/step - loss: 340536896.0000 - val_loss: 340964192.0000\n",
      "Epoch 7/10\n",
      "322/322 [==============================] - 0s 833us/step - loss: 340536992.0000 - val_loss: 340964192.0000\n",
      "Epoch 8/10\n",
      "322/322 [==============================] - 0s 808us/step - loss: 340537088.0000 - val_loss: 340964192.0000\n",
      "Epoch 9/10\n",
      "322/322 [==============================] - 0s 827us/step - loss: 340536800.0000 - val_loss: 340964192.0000\n",
      "Epoch 10/10\n",
      "322/322 [==============================] - 0s 822us/step - loss: 340536864.0000 - val_loss: 340964192.0000\n",
      "Model: \"autoencoder_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_12 (Sequential)  (None, 16)                272       \n",
      "                                                                 \n",
      " sequential_13 (Sequential)  (None, 4, 4)              272       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 544 (2.12 KB)\n",
      "Trainable params: 544 (2.12 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history=autoencoder.fit(flow0, flow0,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(flow0te, flow0te))\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a971b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features = autoencoder.encoder(flow0te).numpy()\n",
    "decoded_features = autoencoder.decoder(encoded_features).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "97a24670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3430, 4, 4)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7ca184c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decotest=decoded_features.reshape(3430,16)\n",
    "decotest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce06f704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5.28510078e-04, 1.09409753e-04, 3.11997515e-04, 8.57325678e-04],\n",
       "        [3.55180547e+04, 1.99797778e+03, 3.07469863e+04, 4.12313633e+04],\n",
       "        [2.47725410e+04, 1.04206555e+03, 2.10976387e+04, 2.71362402e+04],\n",
       "        [1.98934004e-02, 4.61464562e-03, 1.08247399e-02, 3.69368419e-02]],\n",
       "\n",
       "       [[5.26340911e-04, 1.01444624e-04, 3.84208630e-04, 8.79515312e-04],\n",
       "        [3.59365781e+04, 2.32010864e+03, 3.05859199e+04, 4.34134180e+04],\n",
       "        [2.55481582e+04, 9.72561523e+02, 2.17934512e+04, 2.81263184e+04],\n",
       "        [1.62977464e-02, 4.10705898e-03, 9.76962410e-03, 3.15047316e-02]],\n",
       "\n",
       "       [[6.81762409e-04, 1.77410955e-04, 3.98827309e-04, 1.21025881e-03],\n",
       "        [3.31255508e+04, 2.94152344e+03, 2.37066152e+04, 4.45578125e+04],\n",
       "        [2.41896250e+04, 1.32992822e+03, 2.08649492e+04, 2.95634746e+04],\n",
       "        [1.27901454e-02, 4.22914978e-03, 3.79049638e-03, 3.15390863e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[5.97498380e-04, 2.44623981e-04, 2.61162379e-04, 1.56878238e-03],\n",
       "        [3.84928047e+04, 2.64898486e+03, 3.26740762e+04, 4.52563867e+04],\n",
       "        [2.52524980e+04, 9.07782043e+02, 2.21908398e+04, 2.80933301e+04],\n",
       "        [2.52455752e-02, 6.95128459e-03, 1.41550358e-02, 6.51231557e-02]],\n",
       "\n",
       "       [[3.04269895e-04, 1.12963600e-04, 1.66876998e-04, 8.32043705e-04],\n",
       "        [3.28517305e+04, 1.98045874e+03, 2.76206543e+04, 4.09582422e+04],\n",
       "        [2.48107168e+04, 6.93690552e+02, 2.27166777e+04, 2.70391328e+04],\n",
       "        [1.87006127e-02, 3.99797130e-03, 8.29451066e-03, 4.38860208e-02]],\n",
       "\n",
       "       [[3.64066247e-04, 3.72171853e-05, 2.30703634e-04, 4.63649660e-04],\n",
       "        [2.96237930e+04, 1.29794763e+03, 2.61788848e+04, 3.30602266e+04],\n",
       "        [2.47510039e+04, 6.65722656e+02, 2.23474375e+04, 2.58167676e+04],\n",
       "        [8.78512394e-03, 2.75996304e-03, 5.94770862e-03, 2.51138285e-02]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow0te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3bd2cdfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Affichage de la précison de la perte selon l'epoch\n",
    "epochs=range(1,len(history.history['val_loss'])+1)\n",
    "plt.figure(figsize=(15,6))\n",
    "#plt.subplot(121)\n",
    "plt.title('Loss')\n",
    "plt.plot(epochs,history.history['val_loss'],label='val_loss')\n",
    "plt.plot(epochs,history.history['loss'],label='loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "#plt.ylim([0.5,1.5])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ecf8b72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02c4f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modèle Convolutif:\n",
    "class Denoise(Model):\n",
    "  def __init__(self):\n",
    "    super(Denoise, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Input(shape=(4, 4, 1)),\n",
    "      layers.Conv2D(3, (3, 3), activation='relu', padding='same'),\n",
    "      layers.Conv2D(2, (3, 3), activation='relu', padding='same')])\n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Conv2DTranspose(2, kernel_size=3, activation='relu', padding='same'),\n",
    "      layers.Conv2DTranspose(3, kernel_size=3, activation='relu', padding='same'),\n",
    "      layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d36dedeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10288, 16)\n",
      "(10288, 4, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "#Ajustement de la dimension pour l'AE convolutif\n",
    "print(X0tr.shape)\n",
    "co0=X0tr.reshape(X0tr.shape[0],4,4,1).astype('float32')#add an additional dimension to\n",
    "co0te=X0te.reshape(X0te.shape[0],4,4,1).astype('float32')\n",
    "print(co0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba0b39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder2 = Denoise()\n",
    "autoencoder2.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eee01365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 340537920.0000 - val_loss: 340965376.0000\n",
      "Epoch 2/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 340538016.0000 - val_loss: 340965376.0000\n",
      "Epoch 3/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 340538080.0000 - val_loss: 340964960.0000\n",
      "Epoch 4/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 340537600.0000 - val_loss: 340964960.0000\n",
      "Epoch 5/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 340537632.0000 - val_loss: 340964960.0000\n",
      "Epoch 6/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 340537664.0000 - val_loss: 340964960.0000\n",
      "Epoch 7/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 340537568.0000 - val_loss: 340964960.0000\n",
      "Epoch 8/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 340537632.0000 - val_loss: 340964960.0000\n",
      "Epoch 9/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 340537760.0000 - val_loss: 340964960.0000\n",
      "Epoch 10/10\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 340537632.0000 - val_loss: 340964960.0000\n",
      "Model: \"denoise_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_22 (Sequential)  (None, 4, 4, 2)           86        \n",
      "                                                                 \n",
      " sequential_23 (Sequential)  (None, 4, 4, 1)           123       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 209 (836.00 Byte)\n",
      "Trainable params: 209 (836.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history2=autoencoder2.fit(flow0, flow0,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(flow0te, flow0te))\n",
    "autoencoder2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fbf4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
